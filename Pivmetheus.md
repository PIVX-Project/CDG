![](https://www.hicgrp.net/wp-content/uploads/2016/02/work-in-progress-500x261.jpg)
# Disclaimers

#### While this document often makes use of the traditional word "vote", it is important to understand that it only appears to be traditional voting from the users perspective. The internal maths will be in the form of weighted network feedback. This appears to be the only means of accomplishing all of the above named goals. Therefore, it is appropriate to replace the word "vote" with a phrase such as "inform" or "informing" or "information acquirement" or "decision making event". The use of the word "vote" is for mental convenience of the reader only, and the meaning of the word shall be switched to an altered state defined by this paragraph. 

  # Pivmetheus consensus-proposal 
  ### Because an advanced digital assett deserves an advanced consensus model!
 
# 0 Overview

Wherever we begin, we and the world around us all will change with time. In subtle, complex and unpredictable ways. 
Like the performance of a long journey, the decisions that we make will determine where we end more so than the place of our beginning.  
Iteratively, the world will become a reflection of us, and we a reflection of the world.  
Our pathways shall be defined by the rules of the game, both imposed and chosen, understood and misunderstood. 
Because choosing a consensus model is choosing a fate, we believe that the nature of the consensus model chosen is extremely important. We believe it is worth the effort to build the model very carefully and very well.  

The model presented in this document is designed for premium performance, and optimum protection of PIVX future.  Years of research as well as the ideas and experience of many mathematicians, coders, and systems theorists were carefully considered and puzzled together into a document that we believe we can put a great deal of faith in.  Please bear with us as we attempt to explain the reasoning behind the model, the value proposition that it offers, and the fundamental details of it.  

Because of special characteristics of a private exchange medium, this model requires more mathematics as well as more understanding of social systems than other models presented in order to actually deliver on its claims rather than just make them.  Nevertheless, an important part of the design is that the coding effort required should not be more than 30 to 50% higher than what might be spent on some of the other models.  Designing a consensus model, like designing software,  is something of an information game. Therefore, that coding effort will have to be spread over a long period of time, one of the required ingredients of intelligence.  Nevertheless, a functional system should appear long before it is perfected. 

There are many goals of the project (soon to be listed). However, the primary goals are: 

A. To achieve the difficult task of successfully protecting and balancing the values of crucial sub-groups of the community, most notably the small investors. Simultaneously, we wish to protect the economic value of the system.
B. To create a system that is fair, healthy, and long lasting by eliminating the common ugly behaviors of voting/feedback/consensus systems before they get started. 

From the perspective of the current Masternode owners, the shift in voting power under PIVmetheus will appear on the surface to be a loss of roughly 60% of their leverage.  However, leverage is not always such a straight forward issue.  The fact that a small group of individuals are in control of something can make that something less desirable. We expect the leverage to reappear for the Masternode owners as this model should raise the value of their holdings by means of helping to convince new investors that their investments are more safe with a model that protects them and grows their investments.  

Adding a consensus model to a crypto-currency allows it to navigate the future. The same consensus model also allows it to make mistakes, substantially change direction, and/or engage in exploitive behaviors.  A consensus model has the ability to change the currency to the point that it is hardly any more recognizable as the original model.  Furthermore, the consensus model exposes the currency model to a large set of complicated information feedback dynamics that can cause all kinds of unexpected long term problems.  This kind of problem commonly takes the form of parasitic and predator/prey dynamic, but colors and trends in decisions may also have major impacts, both positive and negative.  Because of such issues, designing a consensus model for a crypto-currency is not an easy task and should not at all be taken lightly.  The nature of the consensus model has a major impact on the nature of decisions that come out of it.  

PIVmetheus is designed to provide the highest possible intelligence in its decisions. It is an instrument that uses an understanding of feedback mathematics, intelligence theory and social theory. It weighs and balances the values of differing classes of participants carefully against one another.  It hones each decision into an arrow that points towards success.  In order to do this, it uses carefully designed mathematics that will have strong abilities to actually differentiate between those differing classes of individuals without ever discovering any of their personal details.   This may sound like a bold claim, but careful examinations of the methods will reveal that it can be done.  Then, each of the three layers developed operates together like not stereo, but three angle vision on the subject matter, capable of assessing each circumstance from all three view angles.  

The earlier model presented by presstab clearly had this general intention, but did not include the mechanistic required to properly achieve the goal.  Therefore, one way to view this model is that it’s presstab’s model, re-designed so that it actually works. 

One of the most common issues we have come up against while designing the model is a collection of naive beliefs about human nature and what to expect out of simpler forms of consensus.  Money systems are banks waiting to be robbed. All of history is littered with endless variations of bank robbery. The 2008 housing bubble collapse which motivated the beginning of cryptocurrencies is just one of endless examples. Every time we see a bank vault, it is a reminder of that history.  Simultaneously, bank vaults have proved incapable of solving the bank robbery problem, for rob bankers are just as problematic as bank robbers.  

Market gaming is an old art and profession. We have entire cities full of individuals who excel at gaming. These people play both sides of the market, buying and selling. They get together strategically in groups and use complicated collections of computer-bots, advertising, political and legal leverage, news, and now even social media to push markets up and down without substantially spending their own resources.  Bots turn markets into gambling casinos. Then, they capitalize on the fears and mistakes of large numbers of traders who do not understand that the cards have been intentionally and strategically stacked against them. Cryptos and ICOs are a hot-bed of this kind of activity, which is why China attacked the ICO market.  The public has been robbed of many billions of dollars by pump’n dump ICOs.  Currency supplies of entire nations have been repeatedly destroyed by means of market gaming. Market gaming is so extremely lucrative that it attracts and pays for high class mathematicians, IT talent, and legal talent.  It buys off the opinions of asessment experts.  It even incentivizes the destruction of large numbers of large corporations, for just as money can be made by building something … in the markets, it can be made by destroying something, or even just temporarily damaging it.  It is possible to place bets on either the rise or fall of a market in various ways, and if you can control what you are betting on, then you just might be a robber.  A voting system which lends control of an asset to a small sub-group of the owners of the asset exacerbates the possibilities of using complicated strategies to game wealth away from its proper owners.  Examination of historical records shows that PIVX its self has already fallen prey to classic “pump’n dump” strategies. 

PIVmetheus is designed to put a heavy damper on such dark dynamics by allowing all participants an appropriate quantity of leverage in the system therefore denying control of the currency to small exploitive groups.  Nevertheless, may it please be understood, that cryptocurrencies will eventually require an entire garrison of protection strategies to help make the markets and the currencies safe for the public to use.  This very issue is in fact the purpose of “The Federal Reserve”, “The IMF” and other intelligence groups for their respective bodies of currency.   If installed, PIVmetheus will be a gigantic step towards making crypto-currency safe for public consumption and for the future of man kind.  PIVmetheus will make PIVX into an icon of high intelligence and value in cryptocurrency.  PIVmetheus will also continue to show the world that crypto-currencies can do it better than old, inferior currency models.  

Join with us in an effort to let go of the inadequacies and misunderstandings of the past. Join with us as we build currency safety directly into the currency model its self in a fully transparent fashion. Join with us as we build a world where creation, not manipulation, is the primary value of the economic model.  And may those of us unwilling to create, change their minds and also become creators of a greater future than what can be reached with the old paradigms. 


# 1 Abstract

This proposal is the foremost consensus model for both representing and protecting the small investors in the voting pool.
The following issues to be balanced into this model have been chosen:


1.  <span>Privacy</span>

2.  <span>Simplicity for the end user</span>

3.  <span>Balance, protection, and respect for all groups of the
    community</span>

4.  <span>Maximation of network value. It is understood that network
    value may have modelled by $V=N^2SI$(described in
    detail below)</span>

5.  <span>Maximization of the total utility the PIVX network provides
    for its end users, who are the real source of its value.</span>

6.  <span>Proper representiation for the general usership is of
    particular concern, because the relationship between a social
    networks value and the quantity\*quality of its members is
    approximately quadratic ($N^2$).</span>

7.  <span>Resistance to vote gaming, agressive system tuning, and
    unhealthy feedback</span>


The model presented here is designed to respect the fundamental value model of a cryptocurrency. N^2SI  (described in detail later) It is also designed to respect the various conundrums of voting that result from currently used voting models that are starved of information. The last challenge to be managed is to curtail the arrival of common feedback loop misbehaviors that are evident in current politics as well as common feedback systems. 

 This document describes how a voting architecture may be capable of solving sundry known voting quandries, notably those arising from an inadequate collection of information to make proper decisions, as well as the growth of the unhealthy feedback behaviour which is already recognizable from contemporary political systems, and their tendency to extreme wealth inequality.  A major tool for handling these issues is an advanced balloting system, which allows voters to both rank their preferences, and provide negative feedback.

Consensus information for PIVX denies explicit identity. It must come from the blockchain itself and be private key verifiable.  Under this architecture, it is very difficult, without sacrificing privacy, to prevent the wealthy, from gaining proportionally greater representation, since they can always feign the appearance of many small investors if they so desire. Therefore, in order to protect small investors from virtually being robbed by the wealthy, who can make stronger votes, it remains to provide an incentive for large investors to consolidate their holdings which is greater than their incentives to feign small investors. 

One principal device for this is the provision of leadership opportunities for large stake holders and developers, with simultaneous ensurement of protection for small investors, hence the name "PIVmetheus". Said opportunities  arise from three layered voting. The layers will be named after the elements of the value expression N^2, S, and I. Network support nodes will have an upper hand in the second, 'S' layer, large stake holders ( perhaps developers at some point in time) in a separate 'I' layer, and the rest in the 'N^2' layer.

An important part of this strategy is to keep multiple investor groups competing. If three maligning gold hunters are coming back from the Sierra Madre, with packs full of treasure, there is far greater security than with two, because if any member of the party were to attempt a heist, he'd be outnumbered, two to one. 
How to keep democracy between eleven sheep and thirteen wolves with a  sheeps wardrobe? One way is to keep them in two huts, with hay fed to the first, and beef to the second. The huts vote seperately, may veto decisions, and if a wolf leaves to the sheep bin, the rest get to split his beef. 



# 2 Strategic Weight Analysis



  ## 2.1 Derivation of Approach
  
Many issues, models, and proposals have been considered for the purpose of achieving consensus regarding private cryptocurrency development.  Our model utilizes many components of these other proposals. Simpler models may have been desirable, but could not satisfy all of these important values and conditions:

The fundamental model of network value:

N^2*S*I

where N is the number of nodes and N^2 the number of possible connections, S the strength of the connections and I the intelligence of the connections. 

We can re-state these value dimensions with the terms:  
### Network effect (N^2), Network Support (S), Intelligence (I).  
Having this model of network value means we can analyze the voting feedback system as an optimization problem. According to N^2SI, the network value is clearly extra sensitive to the number of people using the network. Therefore, in deference to some earlier models suggested, this document assumes that protection of the N^2 element of the network, which is primarily represented by the small investors, can not be sacrificed. 

Because of the above privacy requirement, acquiring extremely accurate representations of these three value dimensions is not possible without choosing and using cloaked identity technologies which, while under development, are not yet proven and trustable in our estimation. Therefore, we relegate the possibility of using such identity technologies to future decision making, and strategize to make due with approximations of the three value dimensions noted above. 

A voting layer is a mathematical entity (N^2, S, I ) used to calculate vote value/weight, and not to be confused with a particular type of node on the network. Simultaneously, the voting layers would have strong relationships to the types of nodes and accounts on the network because of the nature of those nodes and accounts. 

#### It is important to understand that the layers are abstract in concept, and that the goal is to approximate the abstractions  successively better with time. Therefore, the original set of parameters put forth by this document is presumed to require future adjustments.  

The Network Support value dimension is the easiest layer to represent in the system because network support data is already on-chain and strongly verifiable. Turtleflax and Veramis presented a model for this, which is close to passable, but hangs up on a few issues, therefore we will have to modify that model somewhat in order to fit it together with the other voting layers. 

For the other two layers, two approximations have been identified, which we believe should share the voting weight equally. The first approximation is the use of voting exponents. In other words, an individuals vote weight is not directly proportional to that individuals holdings, but to the individuals holdings held to an exponent power.  What this means is say for an exponent of 2, An account holding 10 pivs would get 100 votes while for an exponent of 0.5 would an account holding 10 pivs would get only 3.16 votes. The exponent effects different account sizes differently such that exponents smaller than 1 benefit small accounts while exponents greater than 1 benefit large accounts. While "quadratic voting" (exponent 0.5) is a practice of some respect historically, we can not directly follow that path for multiple reasons.  

* Most significantly, the requirement for privacy dictates that simply using square root voting to protect small investors does not work because large investors could too easily game the system and pretend to be many small investors by dividing down their accounts. Therefore, to solve this problem, we merely needed to admit that protecting only small investors is a flawed concept. Benefits given to small investors need to be balanced out by benefits given to large investors. Therefore, a square root vote accompanied by a squared vote gives both small investors and large investors benefits.  The square root vote would be a good approximation for the network effect layer.  The squared vote a good approximation for the intelligence layer, since large investors should take an interest in the development of the currency intelligence, so as to benefit the value of their holdings. Giving a squared voting layer for this purpose should eliminate most motivation for players to game the layers because optimizing ones accounts to benefit the vote count for one layer simultaneously damages ones vote count for the other layer leaving the gamer little to no net benefit for gaming. 
* The second issue with earlier quadratic voting models in circulation is that the sale of votes and redistribution of funds  presents conundrums, so we simply do away with those features. 
* The third issue with earlier quadratic voting is that when we use squared voting as its counterpart for the benefit of large investors, we will likely have too small of a voting sample size for that layer because large holders will be able to outweigh too many smaller holders. Therefore, to aid the voting sample size problem in the squared layer, we suggest moving to exponents other than 0.5 and 2.  Using exponents of 0.6 and 1.66 should solve this problem.  

#### The system will be simple for the end user to use because all of the voting math is handled by computer. The voting/feedback system will not initially require massive amounts of re-coding the system because the voting math will primarily operate on data already present in the system. 

## 2.2 Three Layers
If layers substantially disagree with one another on an event, then there is evidence that the proposals involved need deeper understanding and development. Aligning each of the layers with a legitimate dimension of value further tunes the voting apparatus to protect value in the system. It also shows us the dynamics of that value as we watch the voting play out over time. 


## 2.3 Avoiding Information Starvation


Optimal decisions can't be made from a dearth of the information needed to accurately represent reality. . The infamous 'Tweed' declared, "I don't care who does the electing, so long as I get to do the nominating", because in a two party decision, by the time both candidates are picked, many of the important decisions have already been made. This principle remains widely and effectively exploited in complicated ways. However, proper information management makes it difficult to play these sort of tricks. For those interested, these videos provide additional information concerning "first pass to post" and Tweed tactics, respectively https://www.youtube.com/watch?v=s7tWHJfhiyo&list=PLPZwr9rnuY9pr4InUaLfjmX757UfE-DVY  https://www.youtube.com/watch?v=PJy8vTu66tE

#NOTE- Questionable paragraphs- Historical voting math analysts have studied various voting systems, but normally not under this fundamental understanding. This is evident by the fact that many models of voting systems show up in the studies which are clearly information starved. First past the post voting systems as in common use today being perfect examples.  Therefore, many attempts to create information starved voting algorithms of various flavors all result in a decision making apparatus that misbehaves as is described in the first past the post voting video above.  Furthermore, it is a first step towards Tweed voting. 

In a universe of "for every action, there is an equal and opposite reaction" for example, a voting system that does not include negative feedback (a negative vote) is not representing a fundamental truth about reality.  Reality literally insists on negative feedback, and will find it in whatever way necessary.  If negative feedback isn't explicitly on the ballot, then the ballot is information starved, and invites someone to find out how to play the role of negative feedback. In the first past the post voting system, Negative feedback naturally appears because of the natural narrowing of the party count down to 2. For a two party system, a vote for one party is identical to a vote against the opposing party, and nature's inherent requirement for negative feedback is filled, but at the cost of monopoly and near-monopoly over the candidate pool, Tweed voting style ( https://www.youtube.com/watch?v=PJy8vTu66tE ), which severely damages the voting system by simply removing choices that the voting pool may deeply desire.  Fortunately, PIVX was born with +/0/- voting. Therefore, this issue already partially solved, except that with just one option up for vote and yay or nay to go with it, the two-party system is already also born into the system. Therefore, vote option monopoly is expected. 

To solve the two party system and vote option monopoly problem, we need a combination of +/0/- voting/feedback and the possibility of multiple vote options. Vote options meaning: "I want A or B or C, but not D". Because people can't properly manage a large number of vote options in their minds, more than four vote options may begin to become unmanageable. After long discussions, it was concluded that the best vote counting algorithm available is +/0/- iterative ranked with null option.  

The voter is confronted with a list of options. "Do Nothing" is one of the options, and is automatically listed as a choice. The voter may then add additional options to a list of such choices as being ranked in the voters preferred order above or below "Do Nothing". Options above "Do Nothing" are counted as positive while those below are counted negative.  Those options not moved to a choices list are set to abstain. (0) The voter shows in this case neither preference nor deference for the option abstained and will neigher be weighed for nor against that option during any stage of the counting process. <br />
For each voting layer, (with slight tuning adjustments possible) options that are dominantly listed as negative are counted as blocked (or as requiring extreme positive votes from other layers in order to pass), and may be removed from the options list. Remaining options, always including the "do nothing" option continue to the macro-vote or total group vote where all three layers vote. Each layer providing 1/3 of the total vote weight. The algorithm removes least popular (least positive and lowest ranked) options one at a time until two possible winners remain. This vote may be tuned by adding a default percentage to the "do nothing" option. At this point, votes are counted as + if a remaining option is ranked above the other option by a voter and - if a remaining option is ranked beneath the other option. If a voter does not have both final options ranked on his/her ballot, then that voter has not expressed a preference between the two possible winners, and his/her vote can not be counted. 

A "Must Choose" vote may be implemented by means of removing the "Do Nothing" or Null option. 


## 2.4 Management of Feedback Loop Dynamic
https://www.youtube.com/watch?v=5HNmsBaVmZs  

The above video demonstrates that experts are concerned about government decision processes being influenced by special interest groups. What they blatantly fail to note is that 

* You have multi-billion dollar decisions being made by as little as 11 people. Clearly the "gain factor" is too high, which makes them  susceptible to too much influence created by the heavy monetary weight of the decision. This is a standard feedback loop problem .. or a couple of them in tandem that we might call "high impedence feedback loop" and "high gain factor".  In this Scenereo, the energy in the system is so much greater than the energy in the feedback route, that the feedback information is corrupted by the system energy, creating either distortions, or parasitic patterns, both in the case of current governing practices .. Change the committee size to 110 in stead of 11, and suddenly the group is ten times more expensive, complicated, and difficult to manipulate by special interest groups. The video goes out from the assumption that the committee size can't be questioned.  This is utter nonsense. The true problem they are fighting and don't want to admit is over-centralization. 

* The tuning of the Federal Government voting feedback loop dramatically shifts with population rise because delegate to population ratio is a form of "gain factor". Feedback loop stability is extremely sensitive to loop gain factor. Roughly in the 70's they want to attribute exaggerated corporate influence on federal decisions to transparency laws. Said transparency laws may in fact benefit special interest groups more than the public because those special interest groups are able to pay lobbyists to monitor and influence committee members. However, they fail to properly note that people can't know if their delegates are representing them without transparency, and wish to set up a trusted system. This is an extremely dangerous move to make because .. remember ..  because of increased population size, the tuning of the system is no longer identical to the 1970's and we can not simply trust that the system will then reconfigure back to its 1970's behavior. They fail to consider the possibility that the rise in corporate influence on decisions is also caused by the larger and larger sums of money wielded by corporations (and other groups) doing larger and larger business with more and more people while the federal decision maker teams/committees remain the same size. Setting the federal decision body sizes in stone while the population grows exponentially is basically setting up a feedback loop that constantly re-tunes towards less and less stable numerics without apparently any voice standing up to say ... "hey, this loop is constantly de-tuning its self". We have been begging on hands and knees and praying for exactly this kind of problem to show up. These so called experts fail entirely to suggest the real solution to the problem, which is larger committes and gain factors limited to approximately dunbars number squared (22500). Interestingly, the original constitution used the number 30,000, an acceptable number, but that number was overridden when the size of congress was limited. That limitation appears from a systemstheoretical perspective to be an act of class warfare. However, it is also indistinguishable from being an act of ignorance... an accident (?) which promotes slow domination of oligarchy over time.  

https://en.wikipedia.org/wiki/United_States_congressional_apportionment  

With Current gain factors for congress members in the ballpark of 700,000 (people/representative) this is a number we would drastically reduce if at all possible in any single amplifier gain stage because of the inherent instability of that kind of gain factor. We can eradicate this entire concern with a single move.  Limit the number of accounts a delegate may represent to 30,000 ( just over dunbars number squared .. many people have multiple accounts, justifying higher numbers, but team members have argued to reduce potential powers of single delegates.)  

https://en.wikipedia.org/wiki/Dunbar's_number

 Dunbars number squared represents the concept of "a friend of a friend". If the individual representing you isn't a friend of a friend, then it's doubtful that you are being represented. 



## 2.5 Staking Nodes

Because staking is a network support function, staking node feedback will be counted into the network support layer proportionally with the number of PIVX staked. Unless there is further information to process, Staking nodes and Masternodes may each acquire 50% of this layers vote, although this is a tunable quantity. Many have argued against using vote nodes, leaving vote nodes as a last resort for acquiring adequate vote activity in the N^2 layer. Since vote nodes are a last resort to acquiring adequate N^2 vote, this layer may shift if vote nodes are actually implemented so that vote node holders (not those whom they represent) acquire something like 7% of the total S layer vote.

## 2.6 Masternodes

Masternodes currently present us with a conundrum, because they are pre-defined to be accounts of exactly 10k PIVX. Individuals won't be holding their own preferred coin numbers in those accounts. It is known that many individuals hold quite a few masternodes, but without explicit data, this can not be directly counted into the voting scheme. Unless the community opts to link masternode accounts, masternodes can only be assumed to be components of larger holdings, therefore we reduce their network effect vote by a predefined amount, and increase their intelligence vote by the same amount. 40% decrease/increase. For exponents of 0.6 and 1.66, this equates to the assumption that masternodes will typically be held by people who have 30k PIVX total.  This is an approximation, but without better information, we can not make the approximation more correct. 


## 2.7 Vote Nodes
Because most investors won't have the time and energy to invest in making community decisions, delegation is an important option to consider. Discussions of doing delegation have had rather mixed results, leaving the option for delegation as neither popular nor unpopular. Therefore, we choose to defer the decision as to whether or not delegation is actually used to a later date when it can be elucidated as to how necessary the option is. < br />
The primary value of the concept of vote nodes is in the creation of delegates who can fill that role.  Unlike traditional governing systems, Individuals would not have delegates imposed upon them by majority rule, but will have the freedom to choose their favorite delegate. This helps to get a wealth of information into the decision making system. 

There will not be a limit on the number of delegates other than the natural behavior of a free market. Managing feedback loop dynamics does however demand a limit on the number of accounts that a single delegate can represent. There is no hard limit on that number theoretically, but we will give centralization some benefit of the doubt and use 30,000, which is somewhat higher than Dunbars Number Squared (22500).  Part of the reason for this high estimate is the assumption that many people will have multiple accounts. 

The vote of vote node holders themselves has a place in the network support layer, since they do in fact support the function of the network. The votes that they represent belong in whatever layers they would have influenced otherwise. 

Vote nodes should be allowed to implement delegated proof of stake (DPOS) or staking pools with their adherents. The efforts of those individuals can be supported by DPOS reward percentages, as well as whatever agreements they wish to make with their adherents.  



## 2.8 General Users
All users vote according to PIVX holdings in layers N^2 and I according to the powers (exponents) given to those layers. This includes all node holders. However, there will be a minimum holdings requirement which may change over time. Early suggestion for this number is 500 PIVs. If this number falls too low, it becomes too easy for large holders to steal N^2 vote as well as too easy for uninterested parties to influence decisions. If it rises too high, it becomes too difficult for small stake holders to acquire that voting power. 

## 2.9 The No Dancing Filter
A consensus model deriving its voting weights simply  by what each wallet is holding at voting time would  erroneously overrepresent traders who'd only recently bought their PIVX. Value comes from those who hold their PIVs, as should the votes. A good measure for this is the 'Exponential Moving Average'.
The EMA has a few neat properties. If the holdings on a wallet were to suddenly jump from zero to H, the EMA would steadily respond as

f(t)=H(1-e^{-ct})

If the wallets value jumped back to zero, it's EMA would respond at the rate

f(t)=He^{-ct}

Where (H(t)) is the wallet at time t. To be implemented, the EMA can be calculated by tracking the time and values between transactions. For example, suppose the last transaction occured T in the past, then:

f(H(t)) = (1-e^{-cT})H(t)+e^{-cT}f(H(t-T))


If it happens these calculations are too cumbersome to perform on every transaction, an even further simplified model can be used, which simply approximates a wallets holdings by its contents iteratively say, every two weeks, so that if $e^{-cT}=C$ and the iteration is n, then

f_n=(1-C)H(n)+(C)f_{n-1}

The electronics engineers know this equation as an 'IIR' filter.
Smaller C result in faster t decay.  If C is needed to provide a specific decay rate as fractional reduction per interval T, 0<\lambda<1, the inversion is quite simple.

c=ln(lambda)

## 2.9 Thresholding

### For standard votes

Historically, the concept of a democracy is "majority rule" or 51% takes it. A democracy tends to be predatory as the 3 wolves voting against 2 sheep idea demonstrates.  The concept of a republic was built up to try to alleviate the predation of the democracy. This normally implies a voting threshold of something like 60%. While this may in fact make it more difficult for predators to rule, what we interestingly see is that in this case, 3 wolves can still eat 2 sheep. In neither case have the wolves been separated from the sheep in the voting paradigm, so a wolf votes like a sheep, but eats like a wolf. 

The three layer paradigm we present has something of the ability to separate the wolves and the sheep. This only works because this three layer model projects a new set of roles. It somewhat separates large stake holders from small stake holders. Historically, the wolves tend to be the large stake holders. Interestingly however, if we switch from wolf/sheep dichotomy to sadist/masochist dichotomy then we get something probably a little more true to reality. In the sadist/masochist dichotomy, the masochist occasionally strikes out in desperation and punishes the sadist, which is what the lower class sometimes does to the upper class in political settings. Therefore, the 51% vote tends to result in sadism/masochism .. a pattern normally identified as unhealthy. 

The way these issues work is that people tend to play roles that work. So if you set up a system that disadvantages one role game for a different role game, then you effectively project the new role game onto the public mind in a long-term sort of statistical and tipping point way. So if you want a wolves and sheep game, simply set up a majority rule system. The majority will reliably prey upon the minorities. In what way the majority differs from the minorities. Separating the wolves from the sheep makes it possible to break down the sadist/masochist game. It may not always be possible to do this, in particular because there may be no easy way to make the distinction, but in a setting where the primary issue is account size, the two roles are in all probability distinguishable. Perhaps cryptocurrencies have a little advantage in this respect over other structures. 

By creating a voting layer which substantially advantages an upper class, but that can't be fully enjoyed by an individual who wishes to divide down his accounts to steal lower class protection vote, we are projecting a different role game. We are suggesting to the upper class "don't be a wolf/sadist, be a leader. Be Prometheus and bring fire to man kind! Look at the value equation and see that playing the leadership role raises the value of the system for all, and that falling back to a predator role does you no advantage because it robs from you vestige of leadership." Add to that the inconvenience and problematics of gaming the system, and we expect most large investors to opt for the leadership role because it's just as powerful, but more fun, more open, easier to maintain and more glorious.  So, simply dividing up into the three layers as defined effectively solves the predator/prey problem in this one dimensional dynamic. Therefore, the 60% vote demand for the republic becomes redundant because it's designed to solve a problem that is already solved. We can move the system more easily and safely because protection for the various layers is already built in. 

Unnoted by politicians and attorneys whith whom I have spoken, there is a second reason for a vote requirement substantially over 50%. If we go back to the intelligence equations in various AI models, we will discover that time, or number of iterations of the system, is a crucial element of intelligence algorithmic. We expect it to take more time to get a proposal substantially above 50% vote, and hence, we expect the quality of the resultant proposal to be higher. This conflicts in some cases with the need for an emergency decision, where time simply is not available.  So, what we are seeing here is that once the predator prey problem is pre-solved by layering, we can actually use the voting threshold for a different purpose. We can maximize system intelligence according to time requirement. We can impose a high vote requirement if there is plenty of time, and a lower vote requirement if there is an emergency.  Recalling that PIVX is using +/0/- voting so that >50% is net positive, I believe that reasonable sets of numbers for this are:

* Net Positive, Net Positive, Net Positive (all 3 layers) in case of emergency (such as severe bandwidth problems)
* Net Positive, Net Positive, Net Positive (all 3 layers) and 5% positive total with each layer representing 1/3 of total vote in non-emergency situations. 
* It's probably reasonable to have a vote forcing option where every 5% extra total vote outweighs a 1% layer blocking such that for example 15% total net positive in a non-emergency situation overcomes one of the layers blocking at -2%.

Because of the intention to do away with single-option voting in order to accept a stronger information variety in to the voting option pool, this set of weights does not complete the system. Multiple voting options may pass according to those criteria. In that case, we simply choose the option that has the highest total positive percentage. 

Furthermore, there is the possibility that a large percentage of the public does not deliver information. The earlier threshold of required vote power exercised for a vote to pass was 10%.  A suggestion of 5% has been made in the interim. I believe that starting with 5% is a correct model, to assure mobility, and allowing this value to be altered as history writes something to look at. It will be appropriate to include into voting code a separable matrix structure of tuning parameters which may be both retained and updated over time so as to validate old decisions as well as make new ones. 

## 2.10 Meta-Consensus
It would be naive to assume the ability to anticipate all possible dynamics of a consensus system which involves complex feedback, stochastic inputs, and therefore chaotic movement. Therefore, it is prudent that there are built in procedures for adapting the consensus mechanism itself. However, since Meta-consensus is on a more abstract level, it's impact can be even more unpredictable and sensitive to change than the consensus mechanism itself. For this reason, it is necessary that controls for Meta-Consensus be even more restrictive, with high threshold (see 2.9) and limited manipulability.  

### For Meta-votes 
Meta-votes are just votes with special thresholding for the meta-vote purpose.  These votes are allowed only to operate on the voting system or primary documents of the system its self such as the Manifesto. Any meta-vote operating on normal system decisions is invalid and not to be implemented.  Any normal vote operating on the voting system or primary system documents is similarly invalid and not to be implemented. 

In the case of meta-votes, the structure of the decision making system is in question. It's probably appropriate to have two separate meta-layers for voting.  One for the general manifesto, and a second for any other fundamental document. 


# 3. Implementation

## 3.1 Ballots and Counting


The main issue is that voters should have no need for 'insincere voting'. Rather, they should be prompted to include enough information in their ballot that the voting algorithm can always signify their vote in the most preferable way. First 'pass to post', or basic voting, suffers because its minimal information only really supports a two party system. I expect the  many of you are already familiar with the problems of first pass to post, and may be familiar with the apparent alternatives of both 'iterative ranked' voting, and +,0,- voting, and so may wish to skip some of the following text.

The idea behind iterative ranked is that each ballot consists of an ordered list of the voters preferences. After the first pass, ballots may be counted up, and for each voter whose top pick was for a losing option, his vote gets to be redistributed to his next favored option on a second iteration. 

With +,0,- voting, each option on the ballot recieves a +, -, or nothing. There are two versions of this, since the + and - options may or may not be mutually ranked. The rest of this document will consider only mutually ranked +,0,-. Once the ballots are filled, the +,0,-1 counts are first added together, and as before, votes for the least desired option will be removed from the ballots before an iterated recount. If, at any point, each -1 option is removed from a voters ballot, it is reasonable that said voter gets an implicit -1 count on his least preferred of the +1 options, and similarly if all +1 options are eliminated. Implicit -1 to +1 and reverse should not, of course, be taken in comparison to the null vote
	
However, there is a subtle relation between the two systems.
	PIVX doesn't intend to rely on elections, if they  even choose to have them at all. The sources of analysis many of the folks on PIVX governance have been considering are for picking candidates for a particular role, say 'king', or what have you. However, the PIVX community will be voting on  proposals and ammendments directly, which is uniquely different from an election, in that the 'null' option, to change nothing, is present. OK, so now you may be thinking, sure, all that means is we simply need to include null within the ranks, so that a ballot for three competing options may look something like this: 

  
  1.  <span>B</span>

2.  <span>A</span>

3.  <span>null</span>

4.  <span>C</span>

This voter would rather see nothing get passed than Option C, because it
is ranked below null. Infact, the same voter could have identically
represented his opinions on this +,0,- style ballot:

1.  <span>B +1</span>

2.  <span>A +1</span>

3.  <span>C -1</span>


  
	Since C is -1 here, it is implicit that it is less preferred than null. There is little meaning as to which of these two is better because, infact, they contain identical  identical information, and are 'Isomorphic'. My preference is for, +,0,-1 ballots, as they strike me as cleaner, but it's not a major concern because in the end, there isn't much difference. At the end remains the task of counting up the votes. In our example here- if the C and NULL options are eliminated after the first iterated passes, the algorithm should automatically set preference for B, with +1, against A, with -1. 
	
	 Some PIVX members have cited the 'Condorcet Paradox' and its various derivatives as arguments against ranked systems. However, if you look at them carefully, you may notice that the real problem amounts to the fact that items can get symmetric voting. Objectively, these theorems are not paradoxes at all, but trivial; when all the options get the same number of votes, in any system, obviously that's a problem. 
	 
	 Another concern is how this system could be integrated into more complex macro-model, with multiple layers and so forth. Although I can't specify which is best until the actual full voting algorithm is specified, there are a few very effective ways to integrate votes from different layers:


-   <span>Perhaps the simplest solution is just to add all the votes
    from different voting layers into one pool, differentiating them
    only by the algorithms that determine their weighting</span>

-   <span>A specialized tactic would be to rank the canditates into a
    macrovote, by progressively removing the previous winner from the
    ballots, in order to determine the next most preffered option. You
    could even keep track of the precise margin each winner recieved,
    but then again, if we wanted that functionality we’d have just used
    the first option listed here.</span>

-   <span>it may be strategic to allow layers to block ammendments that
    they have a negative opinion about, meaning the option ranks bellow
    null</span>



## 3.2 Additional Means Of Protecting the N^2 Vote
The N^2 voting layer is the most important voting layer, as it clearly actually represents two dimensions according to the exponent.  Simultaneously, the N^2 layer is also the most difficult layer to successfully capture because capturing it means getting vote data from individuals who are small investors, who are only minimally to moderately interested in the outcome of the system. Besides potential predation from the other layers, voter apathy threatens to weaken the effectiveness of the N^2 voting layer.  Besides the information timing section above. NOTE without adequate protection of the N^2 vote, the model collapses. some options for strengthening this layer are as described below.  Some of these options are more popular than others, so they are listed in an order of reasonable implementation priority. The idea is to implement them starting at the top, and if more N^2 protection seems to be required, then we implement further down the list. Number six is far down the list because it is both unpopular and difficult to implement.  However, early voting count results could show it to be necessary. :

1. Power voting as described above, and exponents of 0.6 and 1.66 for N^2 and I layers respectively. 
2. Easy Voting systems that provide voters an assortment of resources to minimize the effort required to vote. 
3. Slightly raising the exponent of the I layer to 1.72 or some such would additionaly curb predation by other layers without substantially damaging the system.
4. One of the most potent options is to float (make alterable) the N^2 blocking threshold and feed-back tie it to least squares approximations of the exponential function and power law visible in a snapshot of the PIVX distribution.  Significant attempts to steal N^2 vote will be visible in those least squares approximations, and if the distribution starts getting fat at the bottom, we know people are cheating and we can raise the blocking threshold appropriately.  In order to get this right, we need a small research project into identifying the correct account value distributions. Use of this option should allow partial deactivation or down-tuning of the no-dancing filter. 
5. Slight reduction (3-10%) of staking rewards for small accounts should further deter vote stealing by large account holders.
6. Use of delegates, DPOS and vote nodes to allow voters to be represented by those in the study, thereby reducing the effort required to vote.
7. Allowing exchanges to vote explicitly and only in the N^2 layer would bolster the stability of the layer without breaking the N^2SI model. Many have objected to this idea. It's possible in attempt to appease such to reduce the vote weight of the exchanges. 
8. Any other accounts or classes of accounts that can be positively identified as N^2 accounts could be factored into N^2 in order to bolster the meaning and stability of the layer.
9. Anonymous Identity Models (not under consideration at this time)

## 3.4 S layer

The S layer is unique amongst the layers because holding PIVX is not proof of network support function.  Proper proof of network support function can only be acquired by evidence of masternode or staking rewards. Therefore, rather than using current PIVX holdings, we propose counting the PIVX rewarded to an address within a period of time, probably 2 weeks. Then we run that number through the same no dancing filter, or exponential moving average as the other two layers to acquire vote weight so as to substantiate that an account is participating actively over a period of time. We then offer 50% of the vote power of the S layer to masternodes and 50% of it to staking nodes.  While some discussion of creating a concept of “tokens” for accounting vote weights for this layer, we see this as unnecessary at the time, but possibly valuable for future projects. 

If vote nodes become a necessity because of voter apathy, then the vote node holders would acquire 10% of the S layer such that the percentages become 45/45/10.  That 14% would not belong to accounts being represented by vote nodes, but rather to the vote node accounts themselves.  In this case, every vote node representing more than a threshold number of accounts (start with 20) and also  (start with) over 5000 PIVs would share equally with other qualifying  vote nodes the 14% of S layer vote.   

## 3.5 Data Retention
Because of the need to minimize the size of the block chain, It will be an advantage store the vote data separately from the chain. The actual vote results are crucial information and need to be on the chain.  In order to verify the legitimacy of the vote data and the chain, a hash of the vote data blocks should be stored on chain, and something like 50 of the next block creations should sign off the hash of the vote data in digital signatures. Over half of such block creation signatures chain-verifies the vote, and less than that invalidates it. The Vote data shall be retained for roughly 1 year before being archived. Vote data older than one year no longer shall be subject to scrutiny, and shall only be available from any nodes who voluntarily wish to archive the data. 

If the coders however prefer, it should be acceptable to create a second chain, which maintains the vote data separately from the transaction data. 



## 3.6 Onramp
Avoiding an identity model requires extra complexity in this system, which then imposes a step-wise implementation. A reasonable ordering of the steps for implementation is as follows. This schedule should be somewhat flexible, based on the needs of other projects and availability of coding talent. 

1. Create an S layer by adding staking vote together to the currently used masternode vote.
2. Create the N^2 and I layers and options 1 and 2 from section 3.2 as well as a minimal set of measurement instruments for observing the system. Most especially, least squared exponential and power law approximations as well as vote statistics.
3. Observe the system behavior for roughly 1 year.
4. Re-tune parameters and add additional elements from section 3.2 as appears to be appropriate. Adjust system design if necessary.
5. Build more instruments for system observation and observe for another year. 
6. Add more options from 3.2 if necessary, and Re-tune parameters once again. 


## 4 Examples
There are quite a few roles the people who involve themselves with PIVX
may play. Whether it is one or many, these roles will determine their
interests and how they’ll vote. A few of the important ones are listed
below:

**Whales** 

	Fat cats who move large volume, sometimes making visible splashes in the markets. 
	Some are just wealthy people, but 
	others come from financial institutions who trade with other peoples money. 

**Traders** 

	From the exchanges, mostly. They like predictable volatility, often use
	backtested tradebots, may be leveraging borrowed currency (margin), and
	mercurially may be either bullish or bearish, depending on if they plan to 
	buy or sell, respectively.

**Investors**

	Separate from the traders, because they buy and hold long term. Since they are 
	healthy to the system, PIVX incentives 	
	them with  staking and masternode rewards, which lands them in the S layer. 
	
**Developers**

	The ones who design improvements. You, presumably, in the I layer.
	
**Suppliers/Customers**

	Using cryptos to trade either goods or services,
	these people will mostly need low transaction fees, stable currency 
	values, and quality representation in the N^2 layer.


	
Whale traders often proactively push currency value towards the
direction they think it’s already headed. If they are bulls, they may
publically declare it diamonds, and will vote accordingly. If they are bearish, however, whale
traders will be most likely trying to push the price down.
## 4.1 Scenario 1
Suppose some whales from JP Morgan and other financial institutions decide PIVX has potential, although it hasn't been doing all that well lately. First, they act as bears, spreading 'FUD' and doubt, possibly even borrowing PIVX on margin, and selling them. However, as the price dips a bit further, they then buy up a few million $ worth of undervalued PIVX. Some of the bots and traders, seeing how the market has suddenly picked up momentum, following common indicators and technical analysis, also buy in, which drives the price up further. 

Now the price is up, but if the whales tried to sell right then, so would the other traders, and besides, they bought PIVX  because they thought it had potential. Even if they did sell soon, they still wouldn't get a vote because of the EMA. Now they wait, and play the role of investors, slowly buying more pivs, as if they were blowing on a feather, until they decide they would finally like to sell. If PIVX is really growing like investors thought, whales are likely to hold their assets long enough to build a vote on the EMA, a likely to st

Suppose now, the devs from the I layer 


# 5 Discussion and Reference


## 5.1. Options for Optimization to be Discussed These Options Are Not Necessary, but May be Advantageous. 
They have the disadvantage of making it more difficult for people to understand the voting math. 

* account snapshotting combined with exponential-curve and power law analysis and timing allows emphasizing accounts that are relatively certain to not be misrepresenting themselves

* Use of zero knowledge proofs in order to allow ZPIVs to influence voting. 

* allowing exchanges to vote in the network effect layer

* creation of defense and defense intelligence functions to play a role in network support and intelligence layers. Such defense function may be responsible for legal and memetics concerns (Public Relations). 

* use of automatic network tuning mathematics to auto-tune the voting/feedback system.

* use of private identity systems to bolster voting information

* Use of transaction fee information to bolster voting information

* use of iterative voting

* use of vote history to adjust vote weights


## 5.2 Examples of History Measures for a Sytem Guidance Instrument Panel 
Some of these measures have already been implemented. 
See:  http://www.presstab.pw/phpexplorer/PIVX/index.php,  http://pivx.masternodes.pro/

* least squares approximation of negative exponential curve distribution for account values below 10k pivs
* least squares approximation of power law curve distribution for account values above 10k pivs  
* Pivs in Masternodes vs Pivs Staked
* Number of Masternodes
* Number of Staking nodes
* Transaction volume/day
* Layer vs layer vote percentages
* Vote blocking events where a single layer blocks below the blocking threshold
* Number of Vote Nodes
* Average PIVS represented by vote nodes
* Average number of accounts represented by vote nodes
* BTC and USD prices
* rms price volatility measure
* BTC/USD price derivatives
* Estimated price shift time constant (amount of time required to make 63% of a price correction)
* Estimated current value (based primarily off of a single pole fir filter with above time constant)
* Estimated pump pool size
* Estimated dump pool size


## 5.3.  Math Reference (for mathematicians)

The network calculation used to determine a decision based on the individuals votes will take the general form of a 4 layered feed-forward network with the first three layers being non-thresholding layers while the fourth implements a complex system of interrelated thresholds. These four network math layers are not to be confused with the lay-person voting layers. They are calculation machinery, and not human-subjective function description. The input data will take the form of vectors of ternary numbers (+/0/-). 

The first network layer will be the input data.  The first set of weights is derived from chain data, and will weigh the input data into nodes of the second network layer which represents a detailed list of currency related functionalities. The form of the data at this point will be vectors of integers. They will be accompanied by additional scalars, which retain the number of original non-zero votes for each function. The scalars may be used to determine vote percentages. Those functionalities, once summed, will be weighed into the third network layer.

The third network layer will contain a list of the primary value dimensions (or lay-person voting layers). The data in that layer will be summed according to the weight scheme chosen for the three value dimensions. It consists of vectors of integers and scalars

The fourth network layer sums data from the vectors of integers and scalars from the third layer into a mutually suppressive thresholding system. The vector data is split from vectors into scalars. Each node of the fourth layer represents one of the elements of the vectors.  Each node of the fourth layer fills a thresholding function and outputs a single boolean number, all, except for one of which being 0 (not chosen)  while one of which is 1 (chosen). 


## 5.4 Other Reference:

https://en.wikipedia.org/wiki/Electoral_system <br />
https://en.wikipedia.org/wiki/Social_choice_theory  <br />
https://en.wikipedia.org/wiki/Arrow%27s_impossibility_theorem <br />
https://en.wikipedia.org/wiki/Gibbard%E2%80%93Satterthwaite_theorem <br />
https://en.wikipedia.org/wiki/Cardinal_voting <br />
https://en.wikipedia.org/wiki/Condorcet_paradox <br />
http://www.cds.caltech.edu/%7Emurray/books/AM05/pdf/am06-complete_16Sep06.pdf <br />



Contributors:
The information and ideas required to build this document come from a large number of individuals. <br /> 
Turtleflax, Openbaringen, Nitya, Presstab, Alexanderluthor, cryptosi, Grant, derek_hansen, Trismegistus, mgshightech
